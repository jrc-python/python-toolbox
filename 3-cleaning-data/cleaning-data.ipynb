{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data in Python\n",
    "\n",
    "## Data type constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric data or other type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25760 entries, 0 to 25759\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   ride_id          25760 non-null  int64 \n",
      " 1   duration         25760 non-null  object\n",
      " 2   station_A_id     25760 non-null  int64 \n",
      " 3   station_A_name   25760 non-null  object\n",
      " 4   station_B_id     25760 non-null  int64 \n",
      " 5   station_B_name   25760 non-null  object\n",
      " 6   bike_id          25760 non-null  int64 \n",
      " 7   user_type        25760 non-null  int64 \n",
      " 8   user_birth_year  25760 non-null  int64 \n",
      " 9   user_gender      25760 non-null  object\n",
      "dtypes: int64(6), object(4)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "count    25760.000000\n",
      "mean         2.008385\n",
      "std          0.704541\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max          3.000000\n",
      "Name: user_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ride_sharing = pd.read_csv('files/ride_sharing_original.csv')\n",
    "\n",
    "print(ride_sharing.info())\n",
    "print(ride_sharing['user_type'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7 minutes      2322\n",
       "8 minutes      2234\n",
       "9 minutes      2096\n",
       "6 minutes      2091\n",
       "5 minutes      1998\n",
       "               ... \n",
       "100 minutes       1\n",
       "137 minutes       1\n",
       "155 minutes       1\n",
       "193 minutes       1\n",
       "891 minutes       1\n",
       "Name: duration, Length: 172, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing['duration'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration is a string with \"minutes\" at the end.\n",
    "\n",
    "We need to convert it to a numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         duration  duration_time\n",
      "0      12 minutes             12\n",
      "1      24 minutes             24\n",
      "2       8 minutes              8\n",
      "3       4 minutes              4\n",
      "4      11 minutes             11\n",
      "...           ...            ...\n",
      "25755  11 minutes             11\n",
      "25756  10 minutes             10\n",
      "25757  14 minutes             14\n",
      "25758  14 minutes             14\n",
      "25759  29 minutes             29\n",
      "\n",
      "[25760 rows x 2 columns]\n",
      "11.389052795031056\n"
     ]
    }
   ],
   "source": [
    "# Strip duration of minutes\n",
    "ride_sharing['duration_time'] = ride_sharing['duration'].str.strip('minutes')\n",
    "\n",
    "# Convert duration to integer\n",
    "ride_sharing['duration_time'] = ride_sharing['duration_time'].astype('int')\n",
    "\n",
    "# Write an assert statement making sure of conversion\n",
    "assert ride_sharing['duration_time'].dtype == 'int'\n",
    "\n",
    "# Print formed columns and calculate average ride duration \n",
    "print(ride_sharing[['duration','duration_time']])\n",
    "print(ride_sharing['duration_time'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data range constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tire size constraints**\n",
    "\n",
    "Bicycle tire sizes are correctly loaded as a categorical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'category'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ride_sharing = pd.read_csv('files/ride_sharing.csv', dtype={'tire_size':'category'})\n",
    "\n",
    "ride_sharing['tire_size'].dtype.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bicycle tire sizes could be either 26″, 27″ or 29″."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27    8678\n",
       "26    8628\n",
       "29    8454\n",
       "Name: tire_size, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing['tire_size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ride sharing provider decided to set the maximum tire size to be 27″.\n",
    "\n",
    "You can make sure the tire_sizes column has the correct range by first converting it to an integer, then setting and testing the new upper limit of 27″ for tire sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "27    17132\n",
      "26     8628\n",
      "Name: tire_size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert tire_sizes to integer\n",
    "ride_sharing['tire_size'] = ride_sharing['tire_size'].astype('int')\n",
    "\n",
    "# Set all values above 27 to 27\n",
    "ride_sharing.loc[ride_sharing['tire_size'] > 27, 'tire_size'] = 27\n",
    "\n",
    "# Reconvert tire_sizes back to categorical\n",
    "ride_sharing['tire_size'] = ride_sharing['tire_size'].astype('category')\n",
    "\n",
    "# Print tire size description\n",
    "print(ride_sharing['tire_size'].dtype)\n",
    "\n",
    "# Print tire size value counts\n",
    "print(ride_sharing['tire_size'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's introduce a random ride date column to the data, and a bug with dates set in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                            25760\n",
       "mean     2022-06-11 13:04:11.781916672\n",
       "min         2021-11-27 10:23:28.924774\n",
       "25%      2022-03-04 10:23:28.924773888\n",
       "50%      2022-06-11 10:23:28.924773888\n",
       "75%      2022-09-18 10:23:28.924773888\n",
       "max         2022-12-27 10:23:28.924774\n",
       "Name: ride_dt, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ride_sharing = pd.read_csv('files/ride_sharing_original.csv')\n",
    "\n",
    "today = datetime.today()\n",
    "today_last_year = today - relativedelta(years=1)\n",
    "# Introducing a future date bug\n",
    "today_next_month = today + relativedelta(months=1)\n",
    "\n",
    "ride_sharing['ride_dt'] = np.random.choice(pd.date_range(today_last_year, today_next_month), size=ride_sharing.shape[0])\n",
    "ride_sharing['ride_dt'].describe(datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the data to a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_sharing.to_csv('files/ride_sharing_bugged.csv', index=False, date_format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reloading the dataframe, date is now a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          25760\n",
       "unique           396\n",
       "top       2021-12-11\n",
       "freq              94\n",
       "Name: ride_dt, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ride_sharing = pd.read_csv('files/ride_sharing_bugged.csv')\n",
    "\n",
    "ride_sharing['ride_dt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27\n"
     ]
    }
   ],
   "source": [
    "# Convert ride_date to date\n",
    "ride_sharing['ride_dt'] = pd.to_datetime(ride_sharing['ride_dt']).dt.date\n",
    "\n",
    "# Save today's date\n",
    "today = dt.date.today()\n",
    "\n",
    "# Set all in the future to today's date\n",
    "ride_sharing.loc[ride_sharing['ride_dt'] > today, 'ride_dt'] = today\n",
    "\n",
    "# Print maximum of ride_dt column\n",
    "print(ride_sharing['ride_dt'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniqueness constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate values\n",
    "\n",
    "* All columns have the same values\n",
    "\n",
    "| first_name | last_name | address | height | weight |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Justin | Saddlemyer | Boulevard du Jardin Botanique 3, Bruxelles | 193 cm | 87 kg |\n",
    "| Justin | Saddlemyer | Boulevard du Jardin Botanique 3, Bruxelles | 193 cm | 87 kg |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most columns have the same values\n",
    "\n",
    "| first_name | last_name | address | height | weight |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Justin | Saddlemyer | Boulevard du Jardin Botanique 3, Bruxelles | 193 cm | 87 kg |\n",
    "| Justin | Saddlemyer | Boulevard du Jardin Botanique 3, Bruxelles | **194 cm** | 87 kg |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ride_id  duration_time  user_birth_year\n",
      "20        20             16             1998\n",
      "37        20              2             1998\n",
      "55        55             11             1999\n",
      "76        55             11             2099\n",
      "101      101             10             1990\n",
      "126      101             10             1990\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ride_sharing = pd.read_csv('files/ride_sharing.csv')\n",
    "\n",
    "# Find duplicates\n",
    "duplicates = ride_sharing.duplicated('ride_id', keep = False)\n",
    "\n",
    "# Sort your duplicated rides\n",
    "duplicated_rides = ride_sharing[duplicates].sort_values('ride_id')\n",
    "\n",
    "# Print relevant columns of duplicated_rides\n",
    "print(duplicated_rides[['ride_id','duration_time','user_birth_year']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating duplicates\n",
    "\n",
    "* user_birth_year: set to the minimum value\n",
    "* duration: set to the mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop complete duplicates from ride_sharing\n",
    "ride_dup = ride_sharing.drop_duplicates()\n",
    "\n",
    "# Create statistics dictionary for aggregation function\n",
    "statistics = {'user_birth_year': 'min', 'duration_time': 'mean'}\n",
    "\n",
    "# Group by ride_id and compute new statistics\n",
    "ride_unique = ride_dup.groupby('ride_id').agg(statistics).reset_index()\n",
    "\n",
    "# Find duplicated values again\n",
    "duplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)\n",
    "duplicated_rides = ride_unique[duplicates == True]\n",
    "\n",
    "# Assert duplicates are processed\n",
    "assert duplicated_rides.shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membership constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories and membership constraints\n",
    "\n",
    "**Predefined finite set of categories**\n",
    "\n",
    "| Type of data | Example values | Numeric representation |\n",
    "| --- | --- | --- |\n",
    "| Marriage Status | unmarried, married * | 0, 1 |\n",
    "| Household Income Category | 0-20K, 20-40K, ... | 0, 1, ... |\n",
    "| Loan Status | default, payed, no_loan | 0, 1, 2 |\n",
    "\n",
    "<sub>* Marriage status can only be unmarried _or_ married</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating random data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from faker import Faker\n",
    "import datetime\n",
    "\n",
    "def generate_data(records, headers):\n",
    "    # Z+ doesn't exist, we're introducing a bug\n",
    "    blood_types = ['A+', 'A-', 'B+', 'B-', 'AB+', 'AB-', 'O+', 'O-', 'Z+']\n",
    "    marriage_status = ['married', 'unmarried' , 'Married', 'Unmarried', 'MARRIED', 'UNMARRIED', 'M', 'U', ' married', ' unmarried ']\n",
    "\n",
    "    fake = Faker('pt_BR')\n",
    "\n",
    "    with open(\"files/people.csv\", 'wt') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        for i in range(records):\n",
    "            writer.writerow(\n",
    "                {\n",
    "                    \"id\" : i,\n",
    "                    \"prefix\" : fake.prefix(),\n",
    "                    \"name\": fake.name(),\n",
    "                    \"birth_date\" : fake.date(pattern=\"%Y-%m-%d\", end_datetime=datetime.date(2000, 1,1)),\n",
    "                    \"blood_type\" : fake.random_element(elements=blood_types),\n",
    "                    \"marriage_status\": fake.random_element(elements=marriage_status),\n",
    "                    \"household_income\": fake.pyfloat(left_digits=6, right_digits=2, positive=True),\n",
    "                    \"phone_number\" : fake.phone_number(),\n",
    "                    \"email\": fake.email(),\n",
    "                    \"address\" : fake.address(),\n",
    "                    \"zip_code\" : fake.postcode(),\n",
    "                    \"city\" : fake.city(),\n",
    "                    \"state\" : fake.state(),\n",
    "                    \"country\" : fake.country(),\n",
    "                    \"year\": fake.year(),\n",
    "                    \"time\": fake.time(),\n",
    "                    \"url\": fake.url(),\n",
    "                    \"text\": fake.word(),\n",
    "                }\n",
    "            )\n",
    "    \n",
    "\n",
    "records = 1000\n",
    "headers = [\"id\", \"prefix\", \"name\", \"birth_date\", \"blood_type\", \"marriage_status\", \"household_income\", \"phone_number\", \"email\",\n",
    "            \"address\", \"zip_code\", \"city\", \"state\", \"country\", \"year\", \"time\", \"url\", \"text\"]\n",
    "generate_data(records, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>name</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>marriage_status</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email</th>\n",
       "      <th>address</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr.</td>\n",
       "      <td>Felipe Cardoso</td>\n",
       "      <td>1990-02-14</td>\n",
       "      <td>Z+</td>\n",
       "      <td>UNMARRIED</td>\n",
       "      <td>+55 (011) 5054-4164</td>\n",
       "      <td>levi89@example.org</td>\n",
       "      <td>Avenida de Pereira, 3\\nEstoril\\n20245-176 Nogu...</td>\n",
       "      <td>80108073</td>\n",
       "      <td>da Cruz do Norte</td>\n",
       "      <td>Distrito Federal</td>\n",
       "      <td>Trindade e Tobago</td>\n",
       "      <td>2022</td>\n",
       "      <td>23:44:52</td>\n",
       "      <td>https://nascimento.br/</td>\n",
       "      <td>numquam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr.</td>\n",
       "      <td>Sra. Gabrielly Gonçalves</td>\n",
       "      <td>1972-05-31</td>\n",
       "      <td>Z+</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>(031) 2302 6231</td>\n",
       "      <td>tvieira@example.net</td>\n",
       "      <td>Chácara Joaquim da Cunha\\nLagoa\\n34887442 Nasc...</td>\n",
       "      <td>32956-176</td>\n",
       "      <td>Oliveira</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>Ilhas Marshall</td>\n",
       "      <td>2001</td>\n",
       "      <td>00:33:57</td>\n",
       "      <td>https://cardoso.br/</td>\n",
       "      <td>reiciendis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr.</td>\n",
       "      <td>Thales Ramos</td>\n",
       "      <td>1982-01-09</td>\n",
       "      <td>O+</td>\n",
       "      <td>UNMARRIED</td>\n",
       "      <td>+55 84 8090-1714</td>\n",
       "      <td>teixeirarebeca@example.net</td>\n",
       "      <td>Trecho Isabella Monteiro, 58\\nSagrada Família\\...</td>\n",
       "      <td>43804709</td>\n",
       "      <td>Moura</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>Cabo Verde</td>\n",
       "      <td>2008</td>\n",
       "      <td>18:27:05</td>\n",
       "      <td>http://gomes.net/</td>\n",
       "      <td>reprehenderit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr.</td>\n",
       "      <td>Gustavo Henrique Gomes</td>\n",
       "      <td>1991-07-14</td>\n",
       "      <td>A+</td>\n",
       "      <td>UNMARRIED</td>\n",
       "      <td>31 9265 4071</td>\n",
       "      <td>barrosfernando@example.org</td>\n",
       "      <td>Largo Ramos, 24\\nVila Ouro Minas\\n66229-008 Mo...</td>\n",
       "      <td>79006-899</td>\n",
       "      <td>Moura de Teixeira</td>\n",
       "      <td>Distrito Federal</td>\n",
       "      <td>Guernsey</td>\n",
       "      <td>1996</td>\n",
       "      <td>11:09:45</td>\n",
       "      <td>https://da.org/</td>\n",
       "      <td>optio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sra.</td>\n",
       "      <td>Pedro Costa</td>\n",
       "      <td>1989-03-01</td>\n",
       "      <td>O+</td>\n",
       "      <td>UNMARRIED</td>\n",
       "      <td>+55 (084) 9964 0372</td>\n",
       "      <td>mourajoao-gabriel@example.com</td>\n",
       "      <td>Praça Cardoso, 93\\nIpe\\n97557988 Pereira do Oe...</td>\n",
       "      <td>01959-302</td>\n",
       "      <td>Melo</td>\n",
       "      <td>Mato Grosso</td>\n",
       "      <td>Singapura</td>\n",
       "      <td>2012</td>\n",
       "      <td>16:18:36</td>\n",
       "      <td>http://www.ferreira.br/</td>\n",
       "      <td>fugiat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prefix                      name  birth_date blood_type marriage_status  \\\n",
       "id                                                                           \n",
       "0     Dr.            Felipe Cardoso  1990-02-14         Z+       UNMARRIED   \n",
       "1     Sr.  Sra. Gabrielly Gonçalves  1972-05-31         Z+       Unmarried   \n",
       "2     Sr.              Thales Ramos  1982-01-09         O+       UNMARRIED   \n",
       "3     Dr.    Gustavo Henrique Gomes  1991-07-14         A+       UNMARRIED   \n",
       "4    Sra.               Pedro Costa  1989-03-01         O+       UNMARRIED   \n",
       "\n",
       "           phone_number                          email  \\\n",
       "id                                                       \n",
       "0   +55 (011) 5054-4164             levi89@example.org   \n",
       "1       (031) 2302 6231            tvieira@example.net   \n",
       "2      +55 84 8090-1714     teixeirarebeca@example.net   \n",
       "3          31 9265 4071     barrosfernando@example.org   \n",
       "4   +55 (084) 9964 0372  mourajoao-gabriel@example.com   \n",
       "\n",
       "                                              address   zip_code  \\\n",
       "id                                                                 \n",
       "0   Avenida de Pereira, 3\\nEstoril\\n20245-176 Nogu...   80108073   \n",
       "1   Chácara Joaquim da Cunha\\nLagoa\\n34887442 Nasc...  32956-176   \n",
       "2   Trecho Isabella Monteiro, 58\\nSagrada Família\\...   43804709   \n",
       "3   Largo Ramos, 24\\nVila Ouro Minas\\n66229-008 Mo...  79006-899   \n",
       "4   Praça Cardoso, 93\\nIpe\\n97557988 Pereira do Oe...  01959-302   \n",
       "\n",
       "                 city             state            country  year      time  \\\n",
       "id                                                                           \n",
       "0    da Cruz do Norte  Distrito Federal  Trindade e Tobago  2022  23:44:52   \n",
       "1            Oliveira         São Paulo     Ilhas Marshall  2001  00:33:57   \n",
       "2               Moura         São Paulo         Cabo Verde  2008  18:27:05   \n",
       "3   Moura de Teixeira  Distrito Federal           Guernsey  1996  11:09:45   \n",
       "4                Melo       Mato Grosso          Singapura  2012  16:18:36   \n",
       "\n",
       "                        url           text  \n",
       "id                                          \n",
       "0    https://nascimento.br/        numquam  \n",
       "1       https://cardoso.br/     reiciendis  \n",
       "2         http://gomes.net/  reprehenderit  \n",
       "3           https://da.org/          optio  \n",
       "4   http://www.ferreira.br/         fugiat  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people = pd.read_csv('files/people.csv', index_col='id')\n",
    "\n",
    "people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AB-    135\n",
       "AB+    114\n",
       "B+     111\n",
       "O+     109\n",
       "B-     109\n",
       "O-     107\n",
       "A+     106\n",
       "A-     105\n",
       "Z+     104\n",
       "Name: blood_type, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people['blood_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding inconsistent categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Z+'}\n"
     ]
    }
   ],
   "source": [
    "# Correct blood types\n",
    "blood_types = ['A+', 'A-', 'B+', 'B-', 'AB+', 'AB-', 'O+', 'O-']\n",
    "categories = pd.DataFrame(blood_types)\n",
    "categories.columns = ['blood_type']\n",
    "\n",
    "inconsistent_categories = set(people['blood_type']).difference(categories['blood_type'])\n",
    "print(inconsistent_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping inconsistent categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent_categories = set(people['blood_type']).difference(categories['blood_type'])\n",
    "inconsistent_rows = people['blood_type'].isin(inconsistent_categories)\n",
    "inconsistent_data = people[inconsistent_rows]\n",
    "# Drop inconsistent categories and get consistent data only\n",
    "consistent_data = people[~inconsistent_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of consistency errors\n",
    "1. Value inconsistency\n",
    "   * Inconsistent fields: `'married'`, `'Maried'`, `'UNMARRIED'`, `'not married'`...\n",
    "   * _Trailing white spaces: `'_married'` , `' married '` ..;\n",
    "2. Collapsing too many categories to few\n",
    "   * Creating new groups: `0-20K`, `20-40K` categories ... from continuous household income data\n",
    "   * Mapping groups to new ones: Mapping household income categories to 2 `'rich'` , `'poor'`\n",
    "3. Making sure data is of type `category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M              114\n",
       "MARRIED        109\n",
       "married        107\n",
       "Unmarried      102\n",
       "Married        101\n",
       "U              101\n",
       " unmarried      96\n",
       " married        96\n",
       "UNMARRIED       94\n",
       "unmarried       80\n",
       "Name: marriage_status, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people = pd.read_csv('files/people.csv', index_col='id')\n",
    "\n",
    "# Get marriage status column\n",
    "marriage_status = people['marriage_status']\n",
    "marriage_status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing inconsistent values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "married      527\n",
       "unmarried    473\n",
       "Name: marriage_status, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people = pd.read_csv('files/people.csv', index_col='id')\n",
    "\n",
    "# Fix upper and lowercase\n",
    "people['marriage_status'] = people['marriage_status'].str.lower()\n",
    "\n",
    "# Fixing leading and trailing spaces\n",
    "people['marriage_status'] = people['marriage_status'].str.strip()\n",
    "\n",
    "# Fixing incorrect values\n",
    "people.loc[people[\"marriage_status\"] == \"m\", \"marriage_status\"] = \"married\"\n",
    "people.loc[people[\"marriage_status\"] == \"u\", \"marriage_status\"] = \"unmarried\"\n",
    "\n",
    "people['marriage_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collapsing data into categories\n",
    "Create categories out of data: income_group column from income column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50K+       486\n",
       "20K-50K    313\n",
       "0-20K      201\n",
       "Name: income_group, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people = pd.read_csv('files/people.csv', index_col='id')\n",
    "\n",
    "# Using cut() - create category ranges and names\n",
    "ranges = [0, 200000, 500000, np.inf]\n",
    "group_names = ['0-20K', '20K-50K', '50K+']\n",
    "\n",
    "# Create income group column\n",
    "people['income_group'] = pd.cut(people['household_income'], bins=ranges, labels=group_names)\n",
    "people['income_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapsing data into categories\n",
    "\n",
    "**Map categories to fewer ones**: reducing categories in categorical column.\n",
    "\n",
    "operating_system column is: `'Microsoft'`, `'MacOS'`, `'Linux'`, `'IOS'`, `'Android'`\n",
    "\n",
    "operating_system column should become: `'DesktopOS'`, `'MobileOS'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Airline data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible categories for airline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Average</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Somewhat dirty</td>\n",
       "      <td>Very unsafe</td>\n",
       "      <td>Somewhat unsatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty</td>\n",
       "      <td>Somewhat unsafe</td>\n",
       "      <td>Very unsatisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cleanliness           safety          satisfaction\n",
       "0           Clean          Neutral        Very satisfied\n",
       "1         Average        Very safe               Neutral\n",
       "2  Somewhat clean    Somewhat safe    Somewhat satisfied\n",
       "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied\n",
       "4           Dirty  Somewhat unsafe      Very unsatisfied"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categories = pd.read_csv('files/categories.csv', index_col=0)\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the data, we can see that the airline data has the following categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanliness:  ['Clean' 'Average' 'Somewhat clean' 'Unacceptable' 'Somewhat dirty'\n",
      " 'Dirty'] \n",
      "\n",
      "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
      "\n",
      "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satisfied' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied'] \n",
      "\n",
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airlines = pd.read_csv('files/airlines.csv', index_col=0)\n",
    "\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ', airlines['safety'].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inconsistent categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airlines = pd.read_csv('files/airlines.csv', index_col=0)\n",
    "\n",
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remapping categories into ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medium    1711\n",
      "long       685\n",
      "short       81\n",
      "Name: wait_type, dtype: int64\n",
      "weekday    2000\n",
      "weekend     477\n",
      "Name: day_week, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "airlines = pd.read_csv('files/airlines.csv', index_col=0)\n",
    "\n",
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                                labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)\n",
    "\n",
    "print(airlines['wait_type'].value_counts())\n",
    "print(airlines['day_week'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('python-blog')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "061725177886a9677e3a2a695f8172d3e706f5edc71bd44f5c76072fa8e81884"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
